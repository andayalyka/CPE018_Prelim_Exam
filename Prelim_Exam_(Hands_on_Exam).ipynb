{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2j1rVAEsPvF9Mrd+LmSnh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andayalyka/CPE018_Prelim_Exam/blob/main/Prelim_Exam_(Hands_on_Exam).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 018\n",
        "Code Title: | Emerging Technologies in CpE 1 - Fundamentals of Computer Vision\n",
        "1st Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "<u>**ACTIVITY NO.** | **TITLE**\n",
        "**Name** | Andaya, Lyka C.\n",
        "**Section** | CPE31S4\n",
        "**Date Performed**: | October 10, 2023\n",
        "**Date Submitted**: | October 11, 2023\n",
        "**Instructor**: | Engr. Verlyn V. Nojor\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3gqfg0oDv2g"
      },
      "outputs": [],
      "source": [
        "# managers.py\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class CaptureManager(object):\n",
        "    def __init__(self, capture, previewWindowManager=None, shouldMirrorPreview=True):\n",
        "        self.previewWindowManager = previewWindowManager\n",
        "        self.shouldMirrorPreview = shouldMirrorPreview\n",
        "\n",
        "        self._capture = capture\n",
        "        self._channel = 0\n",
        "        self._enteredFrame = False\n",
        "        self._frame = None\n",
        "        self._imageFilename = None\n",
        "        self._videoFilename = None\n",
        "        self._videoEncoding = None\n",
        "        self._VideoWriter = None\n",
        "        self._startTime = None\n",
        "        self._framesElapsed = int(0)\n",
        "        self._fpsEstimate = None\n",
        "\n",
        "    @property\n",
        "    def channel(self):\n",
        "        return self._channel\n",
        "\n",
        "    @channel.setter\n",
        "    def channel(self, value):\n",
        "        if self._channel != value:\n",
        "            self._channel = value\n",
        "            self._frame = None\n",
        "\n",
        "    @property\n",
        "    def frame(self):\n",
        "        if self._enteredFrame and self._frame is None:\n",
        "            _, self._frame = self._capture.retrieve()\n",
        "        return self._frame\n",
        "\n",
        "    @property\n",
        "    def isWritingImage(self):\n",
        "        return self._imageFilename is not None\n",
        "\n",
        "    @property\n",
        "    def isWritingVideo(self):\n",
        "        return self._videoFilename is not None\n",
        "\n",
        "    def enterFrame(self):\n",
        "        \"\"\"Capture the next frame if any.\"\"\"\n",
        "        # First, we will check if any previous frame was exited.\n",
        "        assert not self._enteredFrame, \\\n",
        "            'previous enterFrame() had no matching exitFrame()'\n",
        "\n",
        "        if self._capture is not None:\n",
        "            self._enteredFrame = self._capture.grab()\n",
        "\n",
        "    def exitFrame(self):\n",
        "        \"\"\"Draw to the window, write to files, and release the frame.\"\"\"\n",
        "        # Check whether any grabbed frame is retrievable.\n",
        "        # The getter may retrieve and cache the frame.\n",
        "        if self.frame is None:\n",
        "            self._enteredFrame = False\n",
        "            return\n",
        "\n",
        "        # Update the FPS estimate and related variables.\n",
        "        if self._framesElapsed == 0:\n",
        "            self._startTime = time.time()\n",
        "        else:\n",
        "            timeElapsed = time.time() - self._startTime\n",
        "            self._fpsEstimate = self._framesElapsed / timeElapsed\n",
        "        self._framesElapsed += 1\n",
        "\n",
        "        # Draw to the window, if any.\n",
        "        if self.previewWindowManager is not None:\n",
        "            if self.shouldMirrorPreview:\n",
        "                mirroredFrame = np.flip(self._frame, axis=1).copy() # Corrected a typo\n",
        "                self.previewWindowManager.show(mirroredFrame)\n",
        "            else:\n",
        "                self.previewWindowManager.show(self._frame)\n",
        "\n",
        "        # Write to the image file, if any.\n",
        "        if self.isWritingImage:\n",
        "            cv2.imwrite(self._imageFilename, self._frame)\n",
        "            self._imageFilename = None\n",
        "\n",
        "        # Write to the video file, if any.\n",
        "        self._writeVideoFrame()\n",
        "\n",
        "        # Release the frame.\n",
        "        self._frame = None\n",
        "        self._enteredFrame = False\n",
        "\n",
        "    def writeImage(self, filename):\n",
        "        \"\"\"Write the next exited frame to an image file.\"\"\"\n",
        "        self._imageFilename = filename\n",
        "\n",
        "    def startWritingVideo(self, filename, encoding=1196444237):\n",
        "        \"\"\"Start writing exited frames to a video file.\"\"\"\n",
        "        self._videoFilename = filename\n",
        "        self._videoEncoding = encoding\n",
        "\n",
        "    def stopWritingVideo(self):\n",
        "        \"\"\"Stop writing any frames to a video file.\"\"\"\n",
        "        self._videoFilename = None\n",
        "        self._videoEncoding = None\n",
        "        self._VideoWriter = None # Corrected a typo\n",
        "\n",
        "    def _writeVideoFrame(self):\n",
        "        if not self.isWritingVideo:\n",
        "            return\n",
        "\n",
        "        if self._VideoWriter is None:\n",
        "            fps = self._capture.get(cv2.CAP_PROP_FPS)\n",
        "            if fps == 0.0:\n",
        "                # The capture's FPS is unknown, so use an estimate.\n",
        "                if self._framesElapsed < 20:\n",
        "                    # Wait until more frames elapse so that the estimate is stable.\n",
        "                    return\n",
        "                else:\n",
        "                    fps = self._fpsEstimate\n",
        "\n",
        "                size = (int(self._capture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "                        int(self._capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "                self._VideoWriter = cv2.VideoWriter(self._videoFilename,\n",
        "                                                    self._videoEncoding,\n",
        "                                                    fps, size)\n",
        "\n",
        "            self._VideoWriter.write(self._frame)\n",
        "\n",
        "class WindowManager(object):\n",
        "    def __init__(self, windowName, keypressCallback=None):\n",
        "        self.keypressCallback = keypressCallback\n",
        "        self._windowName = windowName\n",
        "        self._isWindowCreated = False\n",
        "\n",
        "    @property\n",
        "    def isWindowCreated(self):\n",
        "        return self._isWindowCreated\n",
        "\n",
        "    def createWindow(self):\n",
        "        cv2.namedWindow(self._windowName)\n",
        "        self._isWindowCreated = True\n",
        "\n",
        "    def show(self, frame):\n",
        "        cv2.imshow(self._windowName, frame)\n",
        "\n",
        "    def destroyWindow(self):\n",
        "        cv2.destroyWindow(self._windowName)\n",
        "        self._isWindowCreated = False\n",
        "\n",
        "    def processEvents(self):\n",
        "        keycode = cv2.waitKey(1)\n",
        "        if self.keypressCallback is not None and keycode != -1:\n",
        "            # Discard any non-ASCII info coded by gtk.\n",
        "            keycode &= 0xFF\n",
        "            self.keypressCallback(keycode)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cameo.py\n",
        "import cv2\n",
        "from managers import WindowManager, CaptureManager\n",
        "\n",
        "class Cameo(object):\n",
        "    def _init_(self):\n",
        "        self.mode = 0\n",
        "        self._windowManager = WindowManager('Cameo', self.onKeypress)\n",
        "        self._captureManager = CaptureManager(cv2.VideoCapture(0), self._windowManager, True)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Run the main loop.\"\"\"\n",
        "        self._windowManager.createWindow()\n",
        "        while self._windowManager.isWindowCreated:\n",
        "            self._captureManager.enterFrame()\n",
        "            frame = self._captureManager.frame\n",
        "            # TODO: Filter the frame\n",
        "            self._captureManager.exitFrame()\n",
        "            self._windowManager.processEvents()\n",
        "\n",
        "    def onKeypress (self, keycode):\n",
        "        \"\"\"Handle a keypress.\n",
        "        space -> Take a screenshot.\n",
        "        tab -> Start/stop recording a screencast.\n",
        "        escape -> Quit.\n",
        "        \"\"\"\n",
        "        if keycode == 32: # space\n",
        "            self._captureManager.writeImage('screenshot.png')\n",
        "        elif keycode == 9: # tab\n",
        "            if not self._captureManager.isWritingVideo:\n",
        "                self._captureManager.startWritingVideo(\n",
        "                'screencast.avi')\n",
        "            else:\n",
        "                self._captureManager.stopWritingVideo()\n",
        "        elif keycode == 27: # escape\n",
        "            self._windowManager.destroyWindow()\n",
        "\n",
        "if __name__== \"_main_\":\n",
        "    Cameo().run()"
      ],
      "metadata": {
        "id": "MeuU-fHXDxpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modify\n",
        "import cv2\n",
        "import filters\n",
        "from managers import WindowManager, CaptureManager\n",
        "\n",
        "class Cameo (object):\n",
        "    def __init__(self):\n",
        "        self.mode = 0\n",
        "        self._windowManager = WindowManager('Cameo', self.onKeypress)\n",
        "        self._captureManager = CaptureManager(cv2.VideoCapture(0), self._windowManager, True)\n",
        "\n",
        "        # Instances of the Filter Classes\n",
        "        self._blur_filter = filters.BlurFilter()\n",
        "        self._sharpen_filter = filters.SharpenFilter()\n",
        "        self._edges_filter = filters.FindEdgesFilter()\n",
        "        self._emboss_filter = filters.EmbossFilter()\n",
        "        self._cross_process_filter = filters.BGRCrossProcessCurveFilter()\n",
        "        self._canny_filter = filters.CannyEdgeDetectionFilter(lower_threshold=100, upper_threshold=200)\n",
        "        self._contour_filter = filters.ContourDetectionFilter(min_area=-1, color=(0, 255, 0), thickness=2)\n",
        "        self._circle_detection_filter = filters.CircleDetectionFilter()\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Run the main loop.\"\"\"        self._windowManager.createWindow()\n",
        "        while self._windowManager.isWindowCreated:\n",
        "            self._captureManager.enterFrame()\n",
        "            frame = self._captureManager.frame\n",
        "\n",
        "            # Apply the selected filter based on self.mode\n",
        "            if self.mode == 0:\n",
        "                pass # No filter\n",
        "            elif self.mode == 1: # Blur Filter\n",
        "                self._blur_filter.apply(frame, frame)\n",
        "\n",
        "            elif self.mode == 2: # Sharpen Filter\n",
        "                self._sharpen_filter.apply(frame, frame)\n",
        "\n",
        "            elif self.mode == 3: # Edges Filter\n",
        "                self._edges_filter.apply(frame, frame)\n",
        "\n",
        "            elif self.mode == 4: # Emboss Filter\n",
        "                self._emboss_filter.apply(frame, frame)\n",
        "\n",
        "            elif self.mode == 5: # Apply the Cross Process filter\n",
        "                self._cross_process_filter.apply(frame, frame)\n",
        "\n",
        "            elif self.mode == 6: #Apply the Canny filter\n",
        "                self._canny_filter.apply(frame, frame)\n",
        "\n",
        "            elif self.mode == 7: # Apply the Contour Detection Filter\n",
        "                self._contour_filter.apply(frame, frame)\n",
        "\n",
        "            elif self.mode == 8: #Apply Circle Detection Filter\n",
        "                self._circle_detection_filter.apply(frame, frame)\n",
        "\n",
        "            self._captureManager.exitFrame()\n",
        "            self._windowManager.processEvents()\n",
        "\n",
        "    def _filter(self, kern, frame):\n",
        "        self._curveFilter = filters.VConvolutionFilter(kern.kernel)\n",
        "        self._curveFilter.apply(frame, frame)\n",
        "\n",
        "    def onKeypress(self, keycode):\n",
        "        \"\"\" Handle a keypress.\n",
        "        space -> Take a screenshot.\n",
        "        tab -> start/stop recording a screencast.\n",
        "        escape -> Quit.\n",
        "        0 -> No filter\n",
        "        1 -> Blur\n",
        "        2 -> Sharpen\n",
        "        3 -> Edges\n",
        "        4 -> Emboss\n",
        "        5 -> Cross Process\n",
        "        6 -> Canny filter.\n",
        "        7 -> Contour Detection\n",
        "        8 -> Circle Detection.\"\"\"\n",
        "\n",
        "        if keycode == 32: # Space\n",
        "            self._captureManager.writeImage('screenshot.png')\n",
        "\n",
        "        elif keycode == 9: # Tab\n",
        "            if not self._captureManager.isWritingVideo:\n",
        "                self._captureManager.startWritingVideo('screencast.avi')\n",
        "            else:\n",
        "                self._captureManager.stopWritingVideo()\n",
        "\n",
        "        elif keycode == 27: # Escape\n",
        "             self._windowManager.destroyWindow()\n",
        "\n",
        "        elif keycode == 48: # 0\n",
        "             self.mode = 0\n",
        "\n",
        "        elif keycode == 49: # 1\n",
        "              self.mode = 1\n",
        "\n",
        "        elif keycode == 50: # 2\n",
        "              self.mode = 2\n",
        "\n",
        "        elif keycode == 51: # 3\n",
        "              self.mode = 3\n",
        "\n",
        "        elif keycode == 52: # 4\n",
        "              self.mode = 4\n",
        "\n",
        "        elif keycode == 53: # 5+-\n",
        "              self.mode = 5\n",
        "\n",
        "        elif keycode == 54: #6\n",
        "              self.mode = 6\n",
        "\n",
        "        elif keycode == 55: #7\n",
        "              self.mode = 7\n",
        "\n",
        "        elif keycode == 56: #8\n",
        "              self.mode = 8\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Cameo().run()"
      ],
      "metadata": {
        "id": "AiREozQPD6Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filters.py\n",
        "import cv2\n",
        "import numpy\n",
        "import utils\n",
        "\n",
        "\n",
        "\n",
        "def recolorRC(src, dst):\n",
        "\n",
        "    b, g, r = cv2.split(src)\n",
        "    cv2.addWeighted(b, 0.5, g, 0.5, 0, b)\n",
        "    cv2.merge((b, b, r), dst)\n",
        "\n",
        "\n",
        "def recolorRGV(src, dst):\n",
        "\n",
        "    b, g, r = cv2.split(src)\n",
        "    cv2.min(b, g, b)\n",
        "    cv2.min(b, r, b)\n",
        "    cv2.merge((b, g, r), dst)\n",
        "\n",
        "\n",
        "def recolorCMV(src, dst):\n",
        "\n",
        "    b, g, r = cv2.split(src)\n",
        "    cv2.max(b, g, b)\n",
        "    cv2.max(b, r, b)\n",
        "    cv2.merge((b, g, r), dst)\n",
        "\n",
        "\n",
        "def blend(foregroundSrc, backgroundSrc, dst, alphaMask):\n",
        "\n",
        "    # Calculate the normalized alpha mask.\n",
        "    maxAlpha = numpy.iinfo(alphaMask.dtype).max\n",
        "    normalizedAlphaMask = (1.0 / maxAlpha) * alphaMask\n",
        "\n",
        "    # Calculate the normalized inverse alpha mask.\n",
        "    normalizedInverseAlphaMask = \\\n",
        "        numpy.ones_like(normalizedAlphaMask)\n",
        "    normalizedInverseAlphaMask[:] = \\\n",
        "        normalizedInverseAlphaMask - normalizedAlphaMask\n",
        "\n",
        "    # Split the channels from the sources.\n",
        "    foregroundChannels = cv2.split(foregroundSrc)\n",
        "    backgroundChannels = cv2.split(backgroundSrc)\n",
        "\n",
        "    # Blend each channel.\n",
        "    numChannels = len(foregroundChannels)\n",
        "    i = 0\n",
        "    while i < numChannels:\n",
        "        backgroundChannels[i][:] = \\\n",
        "            normalizedAlphaMask * foregroundChannels[i] + \\\n",
        "            normalizedInverseAlphaMask * backgroundChannels[i]\n",
        "        i += 1\n",
        "\n",
        "    # Merge the blended channels into the destination.\n",
        "    cv2.merge(backgroundChannels, dst)\n",
        "\n",
        "\n",
        "def strokeEdges(src, dst, blurKsize = 7, edgeKsize = 5):\n",
        "    if blurKsize >= 3:\n",
        "        blurredSrc = cv2.medianBlur(src, blurKsize)\n",
        "        graySrc = cv2.cvtColor(blurredSrc, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        graySrc = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.Laplacian(graySrc, cv2.CV_8U, graySrc, ksize = edgeKsize)\n",
        "    normalizedInverseAlpha = (1.0 / 255) * (255 - graySrc)\n",
        "    channels = cv2.split(src)\n",
        "    for channel in channels:\n",
        "        channel[:] = channel * normalizedInverseAlpha\n",
        "    cv2.merge(channels, dst)\n",
        "\n",
        "\n",
        "class VFuncFilter(object):\n",
        "    \"\"\"A filter that applies a function to V (or all of BGR).\"\"\"\n",
        "\n",
        "    def __init__(self, vFunc = None, dtype = numpy.uint8):\n",
        "        length = numpy.info(dtype).max + 1\n",
        "        self._vLookupArray = utils.createLookupArray(vFunc, length)\n",
        "\n",
        "    def apply(self, src, dst):\n",
        "        \"\"\"Apply the filter with a BGR or gray source/destination.\"\"\"\n",
        "        srcFlatView = utils.flatView(src)\n",
        "        dstFlatView = utils.flatView(dst)\n",
        "        utils.applyLookupArray(self._vLookupArray, srcFlatView,\n",
        "                               dstFlatView)\n",
        "\n",
        "class VCurveFilter(VFuncFilter):\n",
        "    \"\"\"A filter that applies a curve to V (or all of BGR).\"\"\"\n",
        "\n",
        "    def __init__(self, vPoints, dtype = numpy.uint8):\n",
        "        VFuncFilter.__init__(self, utils.createCurveFunc(vPoints),\n",
        "                             dtype)\n",
        "\n",
        "\n",
        "class BGRFuncFilter(object):\n",
        "    \"\"\"A filter that applies different functions to each of BGR.\"\"\"\n",
        "\n",
        "    def __init__(self, vFunc = None, bFunc = None, gFunc = None,\n",
        "                 rFunc = None, dtype = numpy.uint8):\n",
        "        length = numpy.iinfo(dtype).max + 1\n",
        "        self._bLookupArray = utils.createLookupArray(\n",
        "            utils.createCompositeFunc(bFunc, vFunc), length)\n",
        "        self._gLookupArray = utils.createLookupArray(\n",
        "            utils.createCompositeFunc(gFunc, vFunc), length)\n",
        "        self._rLookupArray = utils.createLookupArray(\n",
        "            utils.createCompositeFunc(rFunc, vFunc), length)\n",
        "\n",
        "    def apply(self, src, dst):\n",
        "        \"\"\"Apply the filter with a BGR source/destination.\"\"\"\n",
        "        b, g, r = cv2.split(src)\n",
        "        utils.applyLookupArray(self._bLookupArray, b, b)\n",
        "        utils.applyLookupArray(self._gLookupArray, g, g)\n",
        "        utils.applyLookupArray(self._rLookupArray, r, r)\n",
        "        cv2.merge([b, g, r], dst)\n",
        "\n",
        "class BGRCurveFilter(BGRFuncFilter):\n",
        "    \"\"\"A filter that applies different curves to each of BGR.\"\"\"\n",
        "\n",
        "    def __init__(self, vPoints = None, bPoints = None,\n",
        "                 gPoints = None, rPoints = None, dtype = numpy.uint8):\n",
        "        BGRFuncFilter.__init__(self,\n",
        "                               utils.createCurveFunc(vPoints),\n",
        "                               utils.createCurveFunc(bPoints),\n",
        "                               utils.createCurveFunc(gPoints),\n",
        "                               utils.createCurveFunc(rPoints), dtype)\n",
        "\n",
        "class BGRCrossProcessCurveFilter(BGRCurveFilter):\n",
        "    \"\"\"A filter that applies cross-process-like curves to BGR.\"\"\"\n",
        "\n",
        "    def __init__(self, dtype = numpy.uint8):\n",
        "        BGRCurveFilter.__init__(\n",
        "            self,\n",
        "            bPoints = [(0,20),(255,235)],\n",
        "            gPoints = [(0,0),(56,39),(208,226),(255,255)],\n",
        "            rPoints = [(0,0),(56,22),(211,255),(255,255)],\n",
        "            dtype = dtype)\n",
        "\n",
        "class BGRPortraCurveFilter(BGRCurveFilter):\n",
        "    \"\"\"A filter that applies Portra-like curves to BGR.\"\"\"\n",
        "\n",
        "    def __init__(self, dtype = numpy.uint8):\n",
        "        BGRCurveFilter.__init__(\n",
        "            self,\n",
        "            vPoints = [(0,0),(23,20),(157,173),(255,255)],\n",
        "            bPoints = [(0,0),(41,46),(231,228),(255,255)],\n",
        "            gPoints = [(0,0),(52,47),(189,196),(255,255)],\n",
        "            rPoints = [(0,0),(69,69),(213,218),(255,255)],\n",
        "            dtype = dtype)\n",
        "\n",
        "class BGRProviaCurveFilter(BGRCurveFilter):\n",
        "    \"\"\"A filter that applies Provia-like curves to BGR.\"\"\"\n",
        "\n",
        "    def __init__(self, dtype = numpy.uint8):\n",
        "        BGRCurveFilter.__init__(\n",
        "            self,\n",
        "            bPoints = [(0,0),(35,25),(205,227),(255,255)],\n",
        "            gPoints = [(0,0),(27,21),(196,207),(255,255)],\n",
        "            rPoints = [(0,0),(59,54),(202,210),(255,255)],\n",
        "            dtype = dtype)\n",
        "\n",
        "class BGRVelviaCurveFilter(BGRCurveFilter):\n",
        "    \"\"\"A filter that applies Velvia-like curves to BGR.\"\"\"\n",
        "\n",
        "    def __init__(self, dtype = numpy.uint8):\n",
        "        BGRCurveFilter.__init__(\n",
        "            self,\n",
        "            vPoints = [(0,0),(128,118),(221,215),(255,255)],\n",
        "            bPoints = [(0,0),(25,21),(122,153),(165,206),(255,255)],\n",
        "            gPoints = [(0,0),(25,21),(95,102),(181,208),(255,255)],\n",
        "            rPoints = [(0,0),(41,28),(183,209),(255,255)],\n",
        "            dtype = dtype)\n",
        "\n",
        "\n",
        "class VConvolutionFilter(object):\n",
        "    \"\"\"A filter that applies a convolution to V (or all of BGR).\"\"\"\n",
        "\n",
        "    def __init__(self, kernel):\n",
        "        self._kernel = kernel\n",
        "\n",
        "    def apply(self, src, dst):\n",
        "        \"\"\"Apply the filter with a BGR or gray source/destination.\"\"\"\n",
        "        cv2.filter2D(src, -1, self._kernel, dst)\n",
        "\n",
        "class BlurFilter(VConvolutionFilter):\n",
        "    \"\"\"A blur filter with a 2-pixel radius.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        kernel = numpy.array([[0.04, 0.04, 0.04, 0.04, 0.04],\n",
        "                              [0.04, 0.04, 0.04, 0.04, 0.04],\n",
        "                              [0.04, 0.04, 0.04, 0.04, 0.04],\n",
        "                              [0.04, 0.04, 0.04, 0.04, 0.04],\n",
        "                              [0.04, 0.04, 0.04, 0.04, 0.04]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class SharpenFilter(VConvolutionFilter):\n",
        "    \"\"\"A sharpen filter with a 1-pixel radius.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        kernel = numpy.array([[-1, -1, -1],\n",
        "                              [-1,  9, -1],\n",
        "                              [-1, -1, -1]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class FindEdgesFilter(VConvolutionFilter):\n",
        "    \"\"\"An edge-finding filter with a 1-pixel radius.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        kernel = numpy.array([[-1, -1, -1],\n",
        "                              [-1,  8, -1],\n",
        "                              [-1, -1, -1]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class EmbossFilter(VConvolutionFilter):\n",
        "    \"\"\"An emboss filter with a 1-pixel radius.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        kernel = numpy.array([[-2, -1, 0],\n",
        "                              [-1,  1, 1],\n",
        "                              [ 0,  1, 2]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class CannyEdgeDetectionFilter(object):\n",
        "    def __init__(self, lower_threshold=100, upper_threshold=200):\n",
        "        self.lower_threshold = lower_threshold\n",
        "        self.upper_threshold = upper_threshold\n",
        "\n",
        "    def apply(self, src, dst):\n",
        "            \"\"\"Apply Canny edge detection to the source image.\"\"\"\n",
        "            # Convert the source image to grayscale\n",
        "            gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Apply Canny edge detection\n",
        "            edges = cv2.Canny(gray, self.lower_threshold, self.upper_threshold)\n",
        "\n",
        "            # Convert the edges image back to BGR format\n",
        "            dst[:] = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "class ContourDetectionFilter(object):\n",
        "    def __init__(self, min_area=100, color=(0, 255, 0), thickness=2):\n",
        "        self.min_area = min_area\n",
        "        self.color = color\n",
        "        self.thickness = thickness\n",
        "\n",
        "    def apply(self, src, dst):\n",
        "        \"\"\"Apply contour detection to the source image.\"\"\"\n",
        "        # Convert the source image to grayscale\n",
        "        gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Cannny edge Detection\n",
        "        edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "        # Find contours in the grayscale image\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Draw contours on the destination image\n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area >= self.min_area:\n",
        "                cv2.drawContours(dst, [contour], -1, self.color, self.thickness)\n",
        "\n",
        "class CircleDetectionFilter(object):\n",
        "    \"\"\"A filter that performs circle detection using Hough Circles.\"\"\"\n",
        "\n",
        "    def __init__(self, dp=1, min_dist=110, param1=110, param2=33, min_radius=10, max_radius=0):\n",
        "        self.dp = dp\n",
        "        self.min_dist = min_dist\n",
        "        self.param1 = param1\n",
        "        self.param2 = param2\n",
        "        self.min_radius = min_radius\n",
        "        self.max_radius = max_radius\n",
        "\n",
        "    def apply(self, src, dst):\n",
        "        \"\"\"Apply circle detection to the source image.\"\"\"\n",
        "        gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "        gray = cv2.medianBlur(gray, 51) # Apply median blur for noise reduction\n",
        "\n",
        "        # Apply the Hough Circle Transform\n",
        "        circles = cv2.HoughCircles(\n",
        "            gray,\n",
        "            cv2.HOUGH_GRADIENT,\n",
        "            dp=self.dp,\n",
        "            minDist=self.min_dist,\n",
        "            param1=self.param1,\n",
        "            param2=self.param2,\n",
        "            minRadius=self.min_radius,\n",
        "            maxRadius=self.max_radius\n",
        "        )\n",
        "\n",
        "        if circles is not None:\n",
        "            circles = numpy.uint16(numpy.around(circles))\n",
        "            for circle in circles[0, :]:\n",
        "                center = (circle[0], circle[1])\n",
        "                radius = circle[2]\n",
        "                cv2.circle(dst, center, radius, (0, 255, 0), 2)\n",
        "                cv2.circle(dst, center, 2, (0, 0, 255), 3)\n"
      ],
      "metadata": {
        "id": "PB776IKGD_LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils.py\n",
        "import cv2\n",
        "import numpy\n",
        "import scipy.interpolate\n",
        "\n",
        "def createFlatView(array):\n",
        "    \"\"\"Return a 1D view of an array of any dimensionality.\"\"\"\n",
        "    flatView = array.view()\n",
        "    flatView.shape = array.size\n",
        "    return flatView\n",
        "\n",
        "def createLookupArray(func, length = 256):\n",
        "    \"\"\"Return a lookup for whole-number inputs to a function.\n",
        "\n",
        "    The lookup values are clamped to [0, length - 1].\n",
        "\n",
        "    \"\"\"\n",
        "    if func is None:\n",
        "        return None\n",
        "    lookupArray = numpy.empty(length)\n",
        "    i = 0\n",
        "    while i < length:\n",
        "        func_i = func(i)\n",
        "        lookupArray[i] = min(max(0, func_i), length - 1)\n",
        "        i += 1\n",
        "    return lookupArray\n",
        "\n",
        "def applyLookupArray(lookupArray, src, dst):\n",
        "    \"\"\"Map a source to a destination using a lookup.\"\"\"\n",
        "    if lookupArray is None:\n",
        "        return\n",
        "    dst[:] = lookupArray[src]\n",
        "\n",
        "def createCurveFunc(points):\n",
        "    \"\"\"Return a function derived from control points.\"\"\"\n",
        "    if points is None:\n",
        "        return None\n",
        "    numPoints = len(points)\n",
        "    if numPoints < 2:\n",
        "        return None\n",
        "    xs, ys = zip(*points)\n",
        "    if numPoints < 4:\n",
        "        kind = 'linear'\n",
        "        # 'quadratic' is not implemented.\n",
        "    else:\n",
        "        kind = 'cubic'\n",
        "    return scipy.interpolate.interp1d(xs, ys, kind,\n",
        "                                      bounds_error = False)\n",
        "\n",
        "def createCompositeFunc(func0, func1):\n",
        "    \"\"\"Return a composite of two functions.\"\"\"\n",
        "    if func0 is None:\n",
        "        return func1\n",
        "    if func1 is None:\n",
        "        return func0\n",
        "    return lambda x: func0(func1(x))\n",
        "\n",
        "def isGray(image):\n",
        "    \"\"\"Return True if the image has one channel per pixel.\"\"\"\n",
        "    return image.ndim < 3\n",
        "\n",
        "def widthHeightDividedBy(image, divisor):\n",
        "    \"\"\"Return an image's dimensions, divided by a value.\"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    return (w/divisor, h/divisor)"
      ],
      "metadata": {
        "id": "UIaxcbefECph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}